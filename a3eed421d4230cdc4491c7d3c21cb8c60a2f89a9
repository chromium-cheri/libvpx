{
  "comments": [
    {
      "key": {
        "uuid": "AAAAXX//wPo\u003d",
        "filename": "vp9/encoder/vp9_encodemb.c",
        "patchSetId": 1
      },
      "lineNbr": 630,
      "author": {
        "id": 1000885
      },
      "writtenOn": "2013-05-01T13:42:03Z",
      "side": 1,
      "message": "btw, I also don\u0027t quite understand why we need a generic quantize function if there is a speed impact - the part where we already do the switch statement above, doesn\u0027t it just mean we can call x-\u003equantize${size} within the switch and be no worse off code-wise, but be much better off speed-wise? That seems much more managable to me, also in terms of making future extensions to the quantize function set (like per-band Q), which can then be handled purely inside quantize.c, instead of needing changes in the callers.",
      "revId": "a3eed421d4230cdc4491c7d3c21cb8c60a2f89a9",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "AAAAXX//wOA\u003d",
        "filename": "vp9/encoder/vp9_encodemb.c",
        "patchSetId": 1
      },
      "lineNbr": 630,
      "author": {
        "id": 1000856
      },
      "writtenOn": "2013-05-01T14:42:32Z",
      "side": 1,
      "message": "is the speed impact you\u0027re talking about from mul, or do you mean more generically?\n\nI don\u0027t think there\u0027s enough data yet to say about the speed impact. I err towards less code is better to start with, since it\u0027s easier to add than delete. Having multiple implementations of the same function for each block size hurts the code cache and overall binary size, and dilutes the profile, in addition to being harder to write and maintain. Forcing the functions all to have the same prototype means that we can put them in a lookup table, which is generally better than a conditional. You can bubble up lookups into the callers and maybe save a few cycles of function call overhead, but once you try to turn the indirect function call into a direct one, you\u0027ve found a place where you\u0027re trading speed for code size and should evaluate it in terms of that.\n\nThere are tradeoffs along several dimensions here, and I don\u0027t by any means think this approach has to be set in stone. But I don\u0027t want to predict the future and future proof this either.",
      "parentUuid": "AAAAXX//wPo\u003d",
      "revId": "a3eed421d4230cdc4491c7d3c21cb8c60a2f89a9",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "AAAAXX//we0\u003d",
        "filename": "vp9/encoder/vp9_encodemb.c",
        "patchSetId": 1
      },
      "lineNbr": 679,
      "author": {
        "id": 1000885
      },
      "writtenOn": "2013-05-01T03:07:05Z",
      "side": 1,
      "message": "I think it\u0027s ok to keep subtract/recon separate, they benefit most from bigger blocksizes since they are relatively simple operations that are largely i/o-constrained, so benefit more from acting on aligned boundaries with aligned sizes, particularly multiples of 16 per line.",
      "revId": "a3eed421d4230cdc4491c7d3c21cb8c60a2f89a9",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "AAAAXX//waE\u003d",
        "filename": "vp9/encoder/vp9_encodemb.c",
        "patchSetId": 1
      },
      "lineNbr": 679,
      "author": {
        "id": 1000856
      },
      "writtenOn": "2013-05-01T05:19:21Z",
      "side": 1,
      "message": "Agree. I have a later commit that splits the forward transform and quant off so it can be called independently, so probably better not to pack too much into this. Though if we consider transforms larger than 32x32, and maybe even at that size, there might be cache considerations that make it advantageous to do as much work on a single block as you can at a time. Too early to tell (and probably doesn\u0027t apply to x86)",
      "parentUuid": "AAAAXX//we0\u003d",
      "revId": "a3eed421d4230cdc4491c7d3c21cb8c60a2f89a9",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "AAAAXX//we4\u003d",
        "filename": "vp9/encoder/vp9_encodemb.c",
        "patchSetId": 1
      },
      "lineNbr": 680,
      "author": {
        "id": 1000885
      },
      "writtenOn": "2013-05-01T03:07:05Z",
      "side": 1,
      "message": "so, the slight problem of this approach is that we can\u0027t do a double 4x4 fdct/quant anymore. not a big problem at this moment (we have very little simd anyway), but something to keep in mind for later for optimization purposes... For haswell (avx2), it\u0027s not unlikely that doing 4 4x4s (or 2 8x8s) at a time is beneficial also.",
      "revId": "a3eed421d4230cdc4491c7d3c21cb8c60a2f89a9",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "AAAAXX//wZo\u003d",
        "filename": "vp9/encoder/vp9_encodemb.c",
        "patchSetId": 1
      },
      "lineNbr": 680,
      "author": {
        "id": 1000856
      },
      "writtenOn": "2013-05-01T05:19:21Z",
      "side": 1,
      "message": "I agree. As we start getting into special casing things for speed, these generic versions could become the reference implementation, and we could write tests that prove that the optimized version matches the reference. I\u0027ve given the 8x4 code this replaces a little bit of thought, but at keeping the complexity out (especially out of the spec) is worthwhile at this point.\n\nWe\u0027ll need to see where this falls on the profile too, may not be as important as in VP8 given the larger transforms available.",
      "parentUuid": "AAAAXX//we4\u003d",
      "revId": "a3eed421d4230cdc4491c7d3c21cb8c60a2f89a9",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "AAAAXX//weM\u003d",
        "filename": "vp9/encoder/vp9_quantize.c",
        "patchSetId": 1
      },
      "lineNbr": 80,
      "author": {
        "id": 1000885
      },
      "writtenOn": "2013-05-01T03:07:05Z",
      "side": 1,
      "message": "is this still simd\u0027able? or do you intend to have simd implementations switch around the txfm_size (n_coeffs) and call the c as a fallback? In that case, maybe add this to vp9_rtcd_defs.sh and give it a _c suffix?\n\nI also wonder if mul should be part of the function signature, it\u0027s more a minor implementation issue, no?",
      "revId": "a3eed421d4230cdc4491c7d3c21cb8c60a2f89a9",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "AAAAXX//wZA\u003d",
        "filename": "vp9/encoder/vp9_quantize.c",
        "patchSetId": 1
      },
      "lineNbr": 80,
      "author": {
        "id": 1000856
      },
      "writtenOn": "2013-05-01T05:19:21Z",
      "side": 1,
      "message": "I think the optimized function should have the prototype of the static quantize() rather than this function, since that doesn\u0027t use any structs as parameters. Could either put the switch in this function or do it in asm. I leave it to whomever writes the first asm version to make that call. This is the hot spot on the profile right now at over 30%, fyi.",
      "parentUuid": "AAAAXX//weM\u003d",
      "revId": "a3eed421d4230cdc4491c7d3c21cb8c60a2f89a9",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "AAAAXX//wP0\u003d",
        "filename": "vp9/encoder/vp9_quantize.c",
        "patchSetId": 1
      },
      "lineNbr": 80,
      "author": {
        "id": 1000885
      },
      "writtenOn": "2013-05-01T13:24:26Z",
      "side": 1,
      "message": "One problem is that this introduces a division (since the value of mul is no longer inlined, so it doesn\u0027t know this is always 1 except for 32x32, where it is 2, i.e. x/2 \u003d\u003d (x+(x\u003c0))\u003e\u003e1, which is divisionless). Anyway I\u0027m fine with handling that once we care about optimizations, but this patch will make the encoder slower, is my point.",
      "parentUuid": "AAAAXX//wZA\u003d",
      "revId": "a3eed421d4230cdc4491c7d3c21cb8c60a2f89a9",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "AAAAXX//wPM\u003d",
        "filename": "vp9/encoder/vp9_quantize.c",
        "patchSetId": 1
      },
      "lineNbr": 80,
      "author": {
        "id": 1000856
      },
      "writtenOn": "2013-05-01T14:42:32Z",
      "side": 1,
      "message": "Sorry, I missed your comment about mul. I\u0027ll remove that.",
      "parentUuid": "AAAAXX//wP0\u003d",
      "revId": "a3eed421d4230cdc4491c7d3c21cb8c60a2f89a9",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    }
  ]
}