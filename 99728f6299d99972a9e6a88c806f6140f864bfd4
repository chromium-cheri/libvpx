{
  "comments": [
    {
      "key": {
        "uuid": "AAAAcX//2ew\u003d",
        "filename": "vp9/encoder/vp9_rdopt.c",
        "patchSetId": 1
      },
      "lineNbr": 633,
      "author": {
        "id": 1000963
      },
      "writtenOn": "2013-07-20T21:46:28Z",
      "side": 1,
      "message": "nice trick / useable in tokenize and detokenize.  probably ought to move to a separate function.",
      "revId": "99728f6299d99972a9e6a88c806f6140f864bfd4",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "AAAAcX//1QE\u003d",
        "filename": "vp9/encoder/vp9_rdopt.c",
        "patchSetId": 1
      },
      "lineNbr": 633,
      "author": {
        "id": 1000885
      },
      "writtenOn": "2013-07-22T21:33:57Z",
      "side": 1,
      "message": "We could take this one step further and do this at the prediction block level rather than the transform block level. Example, let\u0027s say I do a 64x64 pred (inter) and a 8x8 tx, in that case, for each tx block, I merge and splat the contexts for each transform block, and they\u0027re essentially just the inverse of each other. So I can that once for all edges in the predictor block level, then never merge/splat inside the cost, and undo it at the end of the function. That will save some additional cycles...",
      "parentUuid": "AAAAcX//2ew\u003d",
      "revId": "99728f6299d99972a9e6a88c806f6140f864bfd4",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    }
  ]
}