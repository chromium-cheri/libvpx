{
  "comments": [
    {
      "unresolved": true,
      "key": {
        "uuid": "f918064d_c4f83bda",
        "filename": "/COMMIT_MSG",
        "patchSetId": 1
      },
      "lineNbr": 9,
      "author": {
        "id": 1002219
      },
      "writtenOn": "2023-02-09T18:45:26Z",
      "side": 1,
      "message": "At one point these may have generated better code or appeared faster in micro benchmarks on some android devices (ca. 2016). That was just done empirically though, are these documented as having a higher latency?\n\nhttps://bugs.chromium.org/p/webm/issues/detail?id\u003d1299",
      "revId": "459cfc8bae26afde6a16421b6f0e5ff5269ebb80",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "d1d22132_97830bc9",
        "filename": "/COMMIT_MSG",
        "patchSetId": 1
      },
      "lineNbr": 9,
      "author": {
        "id": 1247893
      },
      "writtenOn": "2023-02-10T01:29:52Z",
      "side": 1,
      "message": "We publish a Software Optimization Guide (SWOG) for every micro-architecture which documents the latency and throughput numbers for every instruction; as well as any performance quirks, pitfalls and general programmer recommendations. The SWOG for the Neoverse-N1, for example, can be found here[1].\n\nIn [1], LD4 has a latency of 10 cycles, and we can only execute 1 LD4 every 5 cycles. ST4 has a latency of 9 cycles and only 1 ST4 can be executed every 6 cycles. This is in contrast to LDP having latency 7 and throughput 1, and STP having latency 3 and throughput 1/2 - note section 4.4 in the document on \"Optimizing Memory Copy\".\n\nI think you seeing LD4,ST4 being faster was a result of no \u0027restrict\u0027 keyword, so the compiler used the same registers, and everything executed serially. If this was the case, using fewer instructions - that move much more data around - would be faster, even if each those instructions have higher latency and lower throughput individually.\n\n[1] https://developer.arm.com/documentation/PJDOC-466751330-9707/r4p1/?lang\u003den",
      "parentUuid": "f918064d_c4f83bda",
      "revId": "459cfc8bae26afde6a16421b6f0e5ff5269ebb80",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "87669ab1_9ce30b1a",
        "filename": "/COMMIT_MSG",
        "patchSetId": 1
      },
      "lineNbr": 9,
      "author": {
        "id": 1002219
      },
      "writtenOn": "2023-02-10T03:35:18Z",
      "side": 1,
      "message": "\u003e We publish a Software Optimization Guide (SWOG) for every micro-architecture which documents the latency and throughput numbers for every instruction; as well as any performance quirks, pitfalls and general programmer recommendations. The SWOG for the Neoverse-N1, for example, can be found here[1].\n\u003e \n\u003e In [1], LD4 has a latency of 10 cycles, and we can only execute 1 LD4 every 5 cycles. ST4 has a latency of 9 cycles and only 1 ST4 can be executed every 6 cycles. This is in contrast to LDP having latency 7 and throughput 1, and STP having latency 3 and throughput 1/2 - note section 4.4 in the document on \"Optimizing Memory Copy\".\n\u003e \n\u003e I think you seeing LD4,ST4 being faster was a result of no \u0027restrict\u0027 keyword, so the compiler used the same registers, and everything executed serially. If this was the case, using fewer instructions - that move much more data around - would be faster, even if each those instructions have higher latency and lower throughput individually.\n\u003e \n\u003e [1] https://developer.arm.com/documentation/PJDOC-466751330-9707/r4p1/?lang\u003den\n\nThanks for the explanation and pointer. At the time we would be mostly measuring performance on older Cortex chips. A bump for Neoverse is great, but we want to be careful with mobile devices. I agree with you, though, it probably was just luck. We should go the restrict route and then reassess.",
      "parentUuid": "d1d22132_97830bc9",
      "revId": "459cfc8bae26afde6a16421b6f0e5ff5269ebb80",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "1bebd772_e47f2b59",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1247893
      },
      "writtenOn": "2023-02-09T13:59:26Z",
      "side": 1,
      "message": "Do we have to keep the c89 requirement for libvpx?",
      "revId": "459cfc8bae26afde6a16421b6f0e5ff5269ebb80",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "fc02a1f2_4ab87ebd",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1002219
      },
      "writtenOn": "2023-02-09T18:45:26Z",
      "side": 1,
      "message": "\u003e Do we have to keep the c89 requirement for libvpx?\n\nIt\u0027s unlikely nowadays that it\u0027s necessary, but I\u0027d like to do something coordinated with a release if we were going to go that path. I\u0027ve mentioned to others that restrict should be used more broadly in libaom and libvpx since we\u0027ve seen some nice improvements in libgav1 (and to some extent libwebp, but I didn\u0027t finish up there). For now we can do something like:\n\nhttps://chromium.googlesource.com/codecs/libgav1/+/refs/tags/v0.18.0/src/utils/common.h#45\nhttps://chromium.googlesource.com/webm/libwebp/+/refs/tags/v1.3.0/src/dsp/dsp.h#31\n\nBetter to do that kind of addition in a separate change though.",
      "parentUuid": "1bebd772_e47f2b59",
      "revId": "459cfc8bae26afde6a16421b6f0e5ff5269ebb80",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    }
  ]
}